# ğŸ“Š Data Engineering â€“ Complete & Easy Notes

## ğŸ”¹ What is Data Engineering?

**Data Engineering** is the process of **collecting, processing, storing, and transforming raw data** into a form that can be **analyzed and consumed** by business teams, data analysts, and data scientists.

> **Raw Data â†’ Clean & Structured Data â†’ Useful Insights**

---

## ğŸ”¹ ETL Process (Core of Data Engineering)

**ETL = Extract, Transform, Load**

### 1ï¸âƒ£ Extract

- Collect data from multiple sources
- Examples:
  - Databases
  - APIs
  - Application logs
  - Files (CSV, JSON)

### 2ï¸âƒ£ Transform

- Clean and process raw data
- Tasks include:
  - Removing duplicates
  - Data validation
  - Format conversion
  - Applying business logic
- Example:
  - Currency conversion
  - Timestamp normalization

### 3ï¸âƒ£ Load

- Store transformed data into:
  - Data Warehouse
  - Data Lake

ğŸ“Œ **ETL ensures data is accurate, consistent, and analysis-ready**

---

## ğŸ”¹ What We Learn in Data Engineering

### 1ï¸âƒ£ Handling Large Volume of Data (Volume)

- Modern companies generate **terabytes to petabytes** of data
- Data Engineers build systems that:
  - Store huge datasets
  - Process data efficiently
  - Scale as data grows

---

### 2ï¸âƒ£ Economics of Speed (Processing Speed)

- Faster processing = faster business decisions
- Goal:
  - High performance
  - Low operational cost
- Trade-off between:
  - âš¡ Speed
  - ğŸ’° Cost

---

### 3ï¸âƒ£ Variety of Data

Data exists in multiple formats:

- **Structured Data**
  - Rows and columns
  - Example: MySQL tables

- **Semi-Structured Data**
  - JSON, XML
  - Flexible schema

- **Unstructured Data**
  - Images, videos, logs, text files, emails

ğŸ“Œ Data Engineers must handle **all data types**

---

### 4ï¸âƒ£ Cost Optimization

- Storage is relatively cheap
- Data processing is expensive
- Companies design pipelines to:
  - Store raw data cheaply
  - Process only required data
  - Reduce unnecessary computation

---

## ğŸ”¹ How Companies Acquire Data

### Sources of Data:

1. **User Interactions**
   - Website clicks
   - Mobile app usage
   - Page views, searches, likes

2. **APIs**
   - Internal services
   - External platforms

3. **Third-Party Data**
   - Marketing tools
   - Analytics platforms
   - Partner companies

4. **Transactions**
   - Orders
   - Payments
   - Inventory updates

---

## ğŸ”¹ Data Storage Concepts

### ğŸ”¹ Data Warehouse

- Stores **structured data**
- Optimized for:
  - Analytics
  - Reporting
- Clean and organized

ğŸ“Œ Use cases:

- Business dashboards
- Sales analysis
- Financial reports

---

### ğŸ”¹ Data Lake

- Stores:
  - Raw data
  - Unstructured data
  - Semi-structured data
- Data is stored **as-is**
- Accessed rarely

ğŸ“Œ Why Data Lakes?

- Cheap storage
- Useful for:
  - Machine learning
  - Future analysis
  - Experimental use cases

ğŸ” When needed:

- Data is extracted from Data Lake
- ETL is applied
- Loaded into Data Warehouse

---

### ğŸ”¹ Cloud Storage (Example: AWS)

- Cloud platforms allow:
  - Cheap data storage
  - Pay-as-you-go model
- Storage is cheap
- **Data retrieval and processing are costly**

ğŸ“Œ Hence:

- Companies store raw data in Data Lakes
- Process data only when required
- all the unstructured data is stored in the data lake , which is the scttered data that is generally not needed by the company , or in a very rare case , so when the company need the data form data lake they do ETL and put in the data warehouse generally AWS allows you to put all you data in it for free , but when you try to retrieve it it charges you for retrieving , generally companies keep the data lake in the aws

---

## ğŸ”¹ Data Marts

**Data Marts** are **smaller, subject-specific subsets** of a Data Warehouse.

### Examples:

- Sales Data Mart
- HR Data Mart
- Product Data Mart

ğŸ“Œ Benefits:

- Faster queries
- Easier BI analysis
- Department-specific insights

---

## ğŸ”¹ Overall Data Flow (Architecture)

```

Data Sources
|
|---- ETL ----> Data Warehouse ----> BI / Analytics
|
|------------> Data Lake (raw data)

```

---

## ğŸ”¹ OLTP vs OLAP

### ğŸ”¹ OLTP â€“ Online Transaction Processing

- Handles real-time transactions
- Fast insert, update, delete operations
- Maintains data consistency
- online transaction processing these are the processes where all the transaction related changes and chain of events stored eg > when an order is placed the inventory is updated etc. all of this is stored

ğŸ“Œ Examples:

- Order placement
- Payment processing
- Inventory updates

ğŸ“Œ Databases used:

- MySQL
- PostgreSQL
- Oracle

These are **RDBMS (Relational Database Management Systems)**

---

### ğŸ”¹ OLAP â€“ Online Analytical Processing

- Used for:
  - Data analysis
  - Reporting
- Read-heavy workloads
- Works on historical data

ğŸ“Œ Examples:

- Sales trend analysis
- Customer behavior analysis

ğŸ“Œ Uses:

- Data Warehouses
- Big Data systems

---

## ğŸ”¹ Technology Mapping

| Purpose        | Technology                |
| -------------- | ------------------------- |
| OLTP           | MySQL (RDBMS)             |
| Data Lake      | Cloud Storage (AWS / GCP) |
| Data Warehouse | BigQuery                  |
| Analytics      | BI Tools                  |

ğŸ“Œ **BigQuery**

- SQL-based
- Designed for massive datasets
- Optimized for OLAP workloads

---

## ğŸ”¹ Big Data Storage & Scaling

When data grows, companies use two scaling methods:

### 1ï¸âƒ£ Vertical Scaling

- Increase:
  - CPU
  - RAM
  - Storage
- Limited and expensive

---

### 2ï¸âƒ£ Horizontal Scaling (Distributed Systems)

- Add more machines
- Distribute data across nodes
- Highly scalable and cost-effective

---

## ğŸ”¹ Hadoop Distributed File System (HDFS)

- Open-source distributed file system
- Designed for big data storage
- Stores data across multiple machines
- Provides:
  - Fault tolerance
  - High availability
- Hadoop distributed file system (HDFC) whihc is an opesource software which was created to manage the distributed systems

ğŸ“Œ Forms the foundation of the Big Data ecosystem

---
